# Import necessary libraries
import streamlit as st # For accessing Streamlit secrets and UI elements
import os # For interacting with the operating system (not heavily used here)
from langchain_community.document_loaders import PyPDFLoader # PDF loader (not used directly)
from langchain_text_splitters import RecursiveCharacterTextSplitter # Text splitter (not used directly)
from langchain_google_vertexai import VertexAIEmbeddings # Vertex AI Embeddings (not used directly)
from langchain_core.vectorstores import InMemoryVectorStore # In-memory store (not used directly)
from langchain_openai import OpenAIEmbeddings # OpenAI Embeddings (not used here)
from google.oauth2 import service_account # For Google Cloud credentials
from langchain.chat_models import init_chat_model # Function to initialize chat models
from langchain_core.prompts import PromptTemplate # For creating prompt templates
from langchain_google_community import (
    VertexAISearchRetriever, # Retriever specifically for Google Cloud Vertex AI Search
)

# Load Google Cloud service account credentials from a local JSON file.
# Required for authenticating with Vertex AI services (LLM and Search).
egat_service_account = service_account.Credentials.from_service_account_file(filename="./service_account.json")

# Initialize the Language Model (LLM) using Google Vertex AI.
# Specifies the Gemini model and provides the necessary credentials.
llm = init_chat_model("gemini-2.0-flash-001", model_provider="google_vertexai", credentials=egat_service_account)
# llm = init_chat_model("gpt-4o", model_provider="openai") # Alternative: Initialize OpenAI model (commented out)

# Define the prompt template string for the LLM.
# This template guides the LLM to act as an assistant for EGAT procurement regulations,
# using the retrieved documents as the sole source, adhering to specific rules and formatting.
# Placeholders {retrieved_documents} and {user_prompt} will be filled later.
template="""
‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏ã‡∏∑‡πâ‡∏≠‡∏à‡∏±‡∏î‡∏à‡πâ‡∏≤‡∏á‡∏Ç‡∏≠‡∏á ‡∏Å‡∏ü‡∏ú. ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÅ‡∏ô‡∏ö‡∏à‡∏≤‡∏Å Retrieved Documents ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡πÑ‡∏ß‡πâ‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏´‡∏•‡∏±‡∏Å‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÅ‡∏´‡∏•‡πà‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß

üìå ‡∏Å‡∏é‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö:
1. ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡πÑ‡∏ß‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
2. ‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ï‡πà‡∏á‡πÄ‡∏ï‡∏¥‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ô‡∏≠‡∏Å‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£
3. ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏ß‡πà‡∏≤ ‚Äú‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡πÑ‡∏ß‡πâ‚Äù
4. ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏ï‡∏≠‡∏ö ‡πÉ‡∏´‡πâ‡∏£‡∏∞‡∏ö‡∏∏‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á ‡πÄ‡∏ä‡πà‡∏ô ‡πÄ‡∏•‡∏Ç‡∏´‡∏ô‡πâ‡∏≤, ‡∏´‡∏°‡∏ß‡∏î, ‡∏Ç‡πâ‡∏≠ ‡∏´‡∏£‡∏∑‡∏≠‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠
5. **‡∏ï‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏à‡πâ‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏£‡∏π‡πâ‡∏à‡∏£‡∏¥‡∏á‡∏ï‡∏≠‡∏ö‡πÅ‡∏ö‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ**
6. **‡∏´‡πâ‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡πÄ‡∏ß‡∏¥‡πà‡∏ô‡πÄ‡∏ß‡πâ‡∏≠ ‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏Å‡∏¥‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£**
7. **‡∏ï‡∏≠‡∏ö‡∏ï‡∏£‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô ‡πÅ‡∏•‡∏∞‡∏™‡∏±‡πâ‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢**

üìå ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö:
- ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏™‡∏±‡πâ‡∏ô ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡∏ï‡∏£‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô
- ‡∏ï‡πà‡∏≠‡∏ó‡πâ‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÉ‡∏´‡∏°‡πà‡∏ß‡πà‡∏≤:

  _‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å: ‡∏´‡∏ô‡πâ‡∏≤ XX, ‡∏´‡∏°‡∏ß‡∏î X, ‡∏Ç‡πâ‡∏≠ X_

üìå ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö:
‚Äú‡∏ß‡∏á‡πÄ‡∏á‡∏¥‡∏ô‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 100,000 ‡∏ö‡∏≤‡∏ó ‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á‡πÑ‡∏î‡πâ ‡πÅ‡∏ï‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡∏≠‡∏ô‡∏∏‡∏°‡∏±‡∏ï‡∏¥‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡∏°‡∏µ‡∏≠‡∏≥‡∏ô‡∏≤‡∏à‚Äù

_‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å: ‡∏´‡∏ô‡πâ‡∏≤ 12, ‡∏´‡∏°‡∏ß‡∏î 2, ‡∏Ç‡πâ‡∏≠ 5.1_

‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏≠‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô


## Retrieved Documents !!!!:
{retrieved_documents}

## ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô !!!!:
{user_prompt}
"""

# --- Vertex AI Search Configuration ---
# Replace with your specific Google Cloud project and Vertex AI Search details.
PROJECT_ID = "skooldio-egat-rag-workshop"  # Your Google Cloud Project ID
LOCATION_ID = "global"  # Location of your Vertex AI Search data store (e.g., "us", "eu", "global")
SEARCH_ENGINE_ID = "egat-prompt-rag_1743063246416"  # Your Vertex AI Search App ID (Engine ID) - Note: May not be directly used by retriever if Data Store ID is sufficient
DATA_STORE_ID = "egat-document-store_1743063327319" # Your Vertex AI Search Data Store ID
# --- End Vertex AI Search Configuration ---

# Define the function to handle LLM response generation using RAG with Vertex AI Search.
def llm_response(messages):
    """
    Generates a response using RAG: retrieves relevant documents from Vertex AI Search
    based on the user prompt, formats them into a prompt using the template,
    sends the prompt to the LLM (Gemini), and returns the response.

    Args:
        messages (list): A list of message dictionaries from the chat history.

    Returns:
        str: The content of the LLM's generated response.
    """
    # Get the latest user message content.
    user_prompt = messages[-1]["content"]
    print ("user_prompt", user_prompt) # Print for debugging

    # Initialize the Vertex AI Search Retriever.
    # Connects to the specified data store in your Google Cloud project.
    retriever = VertexAISearchRetriever(
        credentials=egat_service_account, # Pass the loaded credentials
        project_id=PROJECT_ID, # Specify the Google Cloud Project ID
        location_id=LOCATION_ID, # Specify the location of the data store
        data_store_id=DATA_STORE_ID, # Specify the ID of the data store to search within
        max_documents=10, # Set the maximum number of documents to retrieve
        engine_data_type=0, # Corresponds to 'unstructured' data store type
        get_extractive_answers=True, # Enable feature to get direct answers from search results if available
    )
    # Retrieve relevant documents from Vertex AI Search based on the user prompt.
    retrieved_docs = retriever.invoke(user_prompt)

    # Display the retrieved documents in the Streamlit UI within an expander.
    with st.expander("Retrieved Documents"):
        st.write(retrieved_docs)

    # Create a PromptTemplate object from the defined template string.
    custom_template = PromptTemplate.from_template(template)

    # Helper function to replace Thai numerals (‡πê-‡πô) with Arabic numerals (0-9).
    # Useful for consistency or if the LLM handles Arabic numerals better.
    def replace_thai_no(text):
        return text.replace("‡πê", "0").replace("‡πë", "1").replace("‡πí", "2").replace("‡πì", "3").replace("‡πî", "4").replace("‡πï", "5").replace("‡πñ", "6").replace("‡πó", "7").replace("‡πò", "8").replace("‡πô", "9")

    # Format the retrieved documents into a single string for the prompt context.
    # Joins the 'page_content' of each document, applying the numeral replacement.
    docs_content = "\n\n".join(replace_thai_no(doc.page_content) for doc in retrieved_docs)
    # st.write(docs_content) # Optional: Display the formatted context in Streamlit

    # Create the final prompt by invoking the template with the user prompt and formatted documents.
    prompt = custom_template.invoke({"user_prompt": user_prompt, "retrieved_documents":docs_content})

    # Print the final prompt sent to the LLM for debugging.
    print ("Final Prompt", prompt)

    # Invoke the initialized LLM (Gemini) with the final prompt.
    response = llm.invoke(prompt)
    # Return the content part of the LLM's response.
    return response.content