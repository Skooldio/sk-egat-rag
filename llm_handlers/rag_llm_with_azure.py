# Import necessary libraries
import streamlit as st # For accessing Streamlit secrets and UI elements
import os # For interacting with the operating system (e.g., environment variables)
from langchain_community.document_loaders import PyPDFLoader # PDF loader (though not used directly in this RAG flow, might be for future use)
from langchain_text_splitters import RecursiveCharacterTextSplitter # Text splitter (similarly, not used directly here)
from langchain_google_vertexai import VertexAIEmbeddings # Vertex AI Embeddings (not used in this Azure flow)
from langchain_core.vectorstores import InMemoryVectorStore # In-memory vector store (not used in this Azure flow)
from langchain_openai import OpenAIEmbeddings # OpenAI Embeddings (not used directly, as Azure Search handles embeddings)
from google.oauth2 import service_account # Google credentials (not used in this Azure/OpenAI flow)
from langchain.chat_models import init_chat_model # Function to initialize chat models
from langchain_core.prompts import PromptTemplate # For creating prompt templates
from langchain_community.retrievers import AzureAISearchRetriever # Retriever specifically for Azure AI Search

# Set the OpenAI API key from Streamlit secrets. Required for the OpenAI LLM.
os.environ["OPENAI_API_KEY"] = st.secrets.llm.openai_api_key

# Initialize the Language Model (LLM).
# Option 1 (Commented out): Use Google's Gemini via Vertex AI.
# llm = init_chat_model("gemini-2.0-flash-001", model_provider="google_vertexai", credentials=egat_service_account)
# Option 2 (Active): Use OpenAI's GPT-4o model.
llm = init_chat_model("gpt-4o", model_provider="openai")

# Define the prompt template string for the LLM.
# This template guides the LLM to act as an assistant for EGAT procurement regulations,
# using the retrieved documents as the sole source, adhering to specific rules and formatting.
# Placeholders {retrieved_documents} and {user_prompt} will be filled later.
template="""
‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏ã‡∏∑‡πâ‡∏≠‡∏à‡∏±‡∏î‡∏à‡πâ‡∏≤‡∏á‡∏Ç‡∏≠‡∏á ‡∏Å‡∏ü‡∏ú. ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÅ‡∏ô‡∏ö‡∏à‡∏≤‡∏Å Retrieved Documents ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡πÑ‡∏ß‡πâ‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏´‡∏•‡∏±‡∏Å‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÅ‡∏´‡∏•‡πà‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß

üìå ‡∏Å‡∏é‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö:
1. ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡πÑ‡∏ß‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
2. ‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ï‡πà‡∏á‡πÄ‡∏ï‡∏¥‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ô‡∏≠‡∏Å‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£
3. ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏ß‡πà‡∏≤ ‚Äú‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡πÑ‡∏ß‡πâ‚Äù
4. ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏ï‡∏≠‡∏ö ‡πÉ‡∏´‡πâ‡∏£‡∏∞‡∏ö‡∏∏‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á ‡πÄ‡∏ä‡πà‡∏ô ‡πÄ‡∏•‡∏Ç‡∏´‡∏ô‡πâ‡∏≤, ‡∏´‡∏°‡∏ß‡∏î, ‡∏Ç‡πâ‡∏≠ ‡∏´‡∏£‡∏∑‡∏≠‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠
5. **‡∏ï‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏à‡πâ‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏£‡∏π‡πâ‡∏à‡∏£‡∏¥‡∏á‡∏ï‡∏≠‡∏ö‡πÅ‡∏ö‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ**
6. **‡∏´‡πâ‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡πÄ‡∏ß‡∏¥‡πà‡∏ô‡πÄ‡∏ß‡πâ‡∏≠ ‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏Å‡∏¥‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£**
7. **‡∏ï‡∏≠‡∏ö‡∏ï‡∏£‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô ‡πÅ‡∏•‡∏∞‡∏™‡∏±‡πâ‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢**

üìå ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö:
- ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏™‡∏±‡πâ‡∏ô ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡∏ï‡∏£‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô
- ‡∏ï‡πà‡∏≠‡∏ó‡πâ‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÉ‡∏´‡∏°‡πà‡∏ß‡πà‡∏≤:

  _‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å: ‡∏´‡∏ô‡πâ‡∏≤ XX, ‡∏´‡∏°‡∏ß‡∏î X, ‡∏Ç‡πâ‡∏≠ X_

üìå ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö:
‚Äú‡∏ß‡∏á‡πÄ‡∏á‡∏¥‡∏ô‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 100,000 ‡∏ö‡∏≤‡∏ó ‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á‡πÑ‡∏î‡πâ ‡πÅ‡∏ï‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡∏≠‡∏ô‡∏∏‡∏°‡∏±‡∏ï‡∏¥‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡∏°‡∏µ‡∏≠‡∏≥‡∏ô‡∏≤‡∏à‚Äù

_‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å: ‡∏´‡∏ô‡πâ‡∏≤ 12, ‡∏´‡∏°‡∏ß‡∏î 2, ‡∏Ç‡πâ‡∏≠ 5.1_

‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏≠‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô


## Retrieved Documents !!!!:
{retrieved_documents}

## ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô !!!!:
{user_prompt}
"""

# Configure Azure AI Search connection details using environment variables.
# These should ideally be set securely (e.g., via Streamlit secrets or system environment variables).
os.environ["AZURE_AI_SEARCH_SERVICE_NAME"] = "" # Name of your Azure AI Search service
os.environ["AZURE_AI_SEARCH_INDEX_NAME"] = "" # Name of the specific index to query
# WARNING: Hardcoding API keys is insecure. Use st.secrets or environment variables in production.
os.environ["AZURE_AI_SEARCH_API_KEY"] = (
    ""
) # API Key for accessing the Azure AI Search service

# Define the function to handle LLM response generation using RAG with Azure AI Search.
def llm_response(messages):
    """
    Generates a response using RAG: retrieves relevant documents from Azure AI Search
    based on the user prompt, formats them into a prompt using the template,
    sends the prompt to the LLM (GPT-4o), and returns the response.

    Args:
        messages (list): A list of message dictionaries from the chat history.

    Returns:
        str: The content of the LLM's generated response.
    """
    # Get the latest user message content.
    user_prompt = messages[-1]["content"]
    print ("user_prompt", user_prompt) # Print for debugging

    # Initialize the Azure AI Search Retriever.
    # Specifies the field containing the document content ('chunk') and the index name.
    # The API version might need adjustment based on the Azure service features used.
    retriever = AzureAISearchRetriever(
        content_key="chunk", # The field in the Azure index containing the text content
        index_name="", # The target index name
        api_version="2024-11-01-preview", # Azure Search API version
    )

    # Retrieve relevant documents from Azure AI Search based on the user prompt.
    retrieved_docs = retriever.invoke(user_prompt)

    # Display the retrieved documents in the Streamlit UI within an expander.
    with st.expander("Retrieved Documents"):
        st.write(retrieved_docs)

    # Create a PromptTemplate object from the defined template string.
    custom_template = PromptTemplate.from_template(template)

    # Helper function to replace Thai numerals (‡πê-‡πô) with Arabic numerals (0-9).
    # This might be needed if the LLM handles Arabic numerals better or for consistency.
    def replace_thai_no(text):
        return text.replace("‡πê", "0").replace("‡πë", "1").replace("‡πí", "2").replace("‡πì", "3").replace("‡πî", "4").replace("‡πï", "5").replace("‡πñ", "6").replace("‡πó", "7").replace("‡πò", "8").replace("‡πô", "9")

    # Format the retrieved documents into a single string for the prompt context.
    # Joins the 'page_content' of each document, applying the numeral replacement.
    docs_content = "\n\n".join(replace_thai_no(doc.page_content) for doc in retrieved_docs)
    # st.write(docs_content) # Optional: Display the formatted context in Streamlit

    # Create the final prompt by invoking the template with the user prompt and formatted documents.
    prompt = custom_template.invoke({"user_prompt": user_prompt, "retrieved_documents":docs_content})

    # Print the final prompt sent to the LLM for debugging.
    print ("Final Prompt", prompt)

    # Invoke the initialized LLM (GPT-4o) with the final prompt.
    response = llm.invoke(prompt)
    # Return the content part of the LLM's response.
    return response.content